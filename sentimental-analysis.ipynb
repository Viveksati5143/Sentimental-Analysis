{"cells":[{"cell_type":"markdown","metadata":{"_cell_guid":"81ebd5db-eb66-49f2-920d-75fbde680c95","_uuid":"c2f303e138132ed3495fb122dd30141694da10df"},"source":["# I am predicting reviews for null values in dataset using already given reviews."]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"3308441e-d2c1-4271-9e47-f9217a2a15f6","_uuid":"1fb38abd989c00734aafadb7290482db5484e067","trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n","\n","from subprocess import check_output\n","# print(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"markdown","metadata":{"_cell_guid":"d2a5ef6c-143c-46c3-a7bb-802cc36269d4","_uuid":"5fd2c5b476c3371905f898e0cf65b695ea9a7b4d"},"source":["## Importing Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"e23115dc-bf4f-4f75-8eee-9ea94bdf9c38","_uuid":"7bcd1e07ca092777802d58553fed4db595cf709c","collapsed":true,"trusted":true},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","import matplotlib as mpl\n","import nltk.classify.util\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix\n","from sklearn import metrics\n","from sklearn.metrics import roc_curve, auc\n","from nltk.classify import NaiveBayesClassifier\n","import numpy as np\n","import re\n","import string\n","import nltk\n","%matplotlib inline"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ab3c2744-9bab-431e-a1df-32437a143e3d","_uuid":"118bb51d694e5ec0b4f34d96a135966dc4654bd4","trusted":true},"outputs":[],"source":["temp = pd.read_csv(r\"1429_1.csv\")\n","temp.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d989623e-c622-45bd-8232-450f7c06ae01","_uuid":"0f433f3faf598008d06f3aeb0898aec196abd6c7","trusted":true},"outputs":[],"source":["permanent = temp[['reviews.rating' , 'reviews.text' , 'reviews.title' , 'reviews.username']]\n","print(permanent.isnull().sum()) #Checking for null values\n","permanent.head()\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"fa18f4f5-020c-4676-9325-de8d39488570","_uuid":"5d9d31976e08c35ee092bba77f80aa9badbf35c3"},"source":["## Filtering null values"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8d90d3f2-778f-4228-a950-aa3ed439a980","_uuid":"f6d87f465ec602326168512617dfc72f69860e15","trusted":true},"outputs":[],"source":["check =  permanent[permanent[\"reviews.rating\"].isnull()]\n","check.head()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"4774bce2-b3fd-40b1-99b3-9589655fd61c","_uuid":"e8a79c132dae52eba3fcad5935cb50f48820d3c5"},"source":["## Filtering not null values"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"ef1db1ef-32c5-400a-8956-88bc33adc3c2","_uuid":"0619937b511a032295187fe76b368adbca2a8c49","trusted":true},"outputs":[],"source":["senti= permanent[permanent[\"reviews.rating\"].notnull()]\n","permanent.head()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"fb75db3a-585b-4de7-9607-c9f3035283f2","_uuid":"d92a6d52db6097b71f35824c93342920026b4195"},"source":["## Classifying text as postive and negative"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"41696a53-19f1-4275-a5f9-8f2be0109afd","_uuid":"3e73d8ce154f6e0ccaa7b712d8f05acc19b0d978","trusted":true},"outputs":[],"source":["senti[\"senti\"] = senti[\"reviews.rating\"]>=4\n","senti[\"senti\"] = senti[\"senti\"].replace([True , False] , [\"pos\" , \"neg\"])"]},{"cell_type":"markdown","metadata":{"_cell_guid":"8f143c16-6ac1-45d2-ae1a-85906f21adb0","_uuid":"1c678f15281647e1acba8d5c2f5992933d058c0a"},"source":["## Count of reviews"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"89c5d3fc-3531-40a8-a0b8-1ab614fb6acd","_uuid":"770aca195535cf73923aaef37bf24745ec54514e","trusted":true},"outputs":[],"source":["senti[\"senti\"].value_counts().plot.bar()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"8d6567c4-e499-4737-b91e-764b878d5730","_uuid":"7ff0f235f0d8c4b80e6a603b0c264f91e606c3a9"},"source":["As we can see data is unbalanced so this will create problem for model but, will take this data as it is and will predict our reviews."]},{"cell_type":"markdown","metadata":{"_cell_guid":"c56d24f3-eff5-45f5-910e-162a0b03c710","_uuid":"aaaf33172865ca5cc532c1c572b8cf1d07f9cd92"},"source":["## Cleaning text"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2fea4cdc-cb0b-4e01-9b67-3fc8471d1335","_uuid":"9ac6b57241511ac14d574531f7161ddcdb00cc8b","trusted":true},"outputs":[],"source":["import nltk.classify.util\n","from nltk.classify import NaiveBayesClassifier\n","import numpy as np\n","import re\n","import string\n","import nltk\n","\n","cleanup_re = re.compile('[^a-z]+')\n","def cleanup(sentence):\n","    sentence = str(sentence)\n","    sentence = sentence.lower()\n","    sentence = cleanup_re.sub(' ', sentence).strip()\n","    #sentence = \" \".join(nltk.word_tokenize(sentence))\n","    return sentence\n","\n","senti[\"Summary_Clean\"] = senti[\"reviews.text\"].apply(cleanup)\n","check[\"Summary_Clean\"] = check[\"reviews.text\"].apply(cleanup)\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a35ea44f-1edc-4730-9e5b-93e250a2ccfe","_uuid":"c7e93168c642d5c091405ce85b0744de5c0ca354"},"source":["## Splitting Train and Test Data"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"af7c6e3d-bdb5-4dbb-8e5d-99e1f869601d","_uuid":"f843f7a6c8731061183855b15a23a806754ce7a6","trusted":true},"outputs":[],"source":["split = senti[[\"Summary_Clean\" , \"senti\"]]\n","train=split.sample(frac=0.8,random_state=200)\n","test=split.drop(train.index)"]},{"cell_type":"markdown","metadata":{"_cell_guid":"7fbe6570-b5e9-4845-8a03-d2c67927581c","_uuid":"27058ae188493485ca449bac9871de9437da3d05"},"source":["## Feature Extracter for NLTK Naive bayes classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8ed22181-6e32-4739-bb66-36a8428906d1","_uuid":"5f2f34d01b7014bcdb9cd67133490fe8d48c9b76","collapsed":true,"trusted":true},"outputs":[],"source":["def word_feats(words):\n","    features = {}\n","    for word in words:\n","        features [word] = True\n","    return features\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8657105a-6d77-4765-8e54-6ef8ab1012ba","_uuid":"75d8848661e27e8d4dde26a15e971368be3c008f","trusted":true},"outputs":[],"source":["train[\"words\"] = train[\"Summary_Clean\"].str.lower().str.split()\n","test[\"words\"] = test[\"Summary_Clean\"].str.lower().str.split()\n","check[\"words\"] = check[\"Summary_Clean\"].str.lower().str.split()\n","\n","train.index = range(train.shape[0])\n","test.index = range(test.shape[0])\n","check.index = range(check.shape[0])\n","prediction =  {} ## For storing results of different classifiers\n","\n","train_naive = []\n","test_naive = []\n","check_naive = []\n","\n","for i in range(train.shape[0]):\n","    train_naive = train_naive +[[word_feats(train[\"words\"][i]) , train[\"senti\"][i]]]\n","for i in range(test.shape[0]):\n","    test_naive = test_naive +[[word_feats(test[\"words\"][i]) , test[\"senti\"][i]]]\n","for i in range(check.shape[0]):\n","    check_naive = check_naive +[word_feats(check[\"words\"][i])]\n","\n","\n","classifier = NaiveBayesClassifier.train(train_naive)\n","print(\"NLTK Naive bayes Accuracy : {}\".format(nltk.classify.util.accuracy(classifier , test_naive)))\n","classifier.show_most_informative_features(5)\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"5ee3bb7e-55b8-408a-8aee-ef8f5123bf94","_uuid":"ad1d1c3c4520884fe350be4a10e7992d792122fe"},"source":["## predicting result of nltk classifier"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"aa113bf9-2b13-4fbb-9201-82ad8ee1d9e0","_uuid":"2f7a02131c869647522aafeebc5ca18819621e18","trusted":true},"outputs":[],"source":["y =[]\n","only_words= [test_naive[i][0] for i in range(test.shape[0])]\n","for i in range(test.shape[0]):\n","    y = y + [classifier.classify(only_words[i] )]\n","prediction[\"Naive\"]= np.asarray(y)\n","\n","y1 = []\n","for i in range(check.shape[0]):\n","    y1 = y1 + [classifier.classify(check_naive[i] )]\n","\n","check[\"Naive\"] = y1"]},{"cell_type":"markdown","metadata":{"_cell_guid":"9358d370-3d07-4052-b9f7-68177915bf0c","_uuid":"739a8abfe26a70358ddb274cab0c3acb996e0a27"},"source":["## Now we are bulding Countvector and Tfidf vector for train , test ,check data"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8f9f3477-896b-4de7-a70a-09724bd5b929","_uuid":"e278d75a576fed5542d677750f1b68ebbd947061","collapsed":true,"trusted":true},"outputs":[],"source":["from wordcloud import STOPWORDS\n","\n","from sklearn.feature_extraction.text import TfidfTransformer\n","from sklearn.feature_extraction.text import CountVectorizer\n","stopwords = set(STOPWORDS)\n","stopwords.remove(\"not\")\n","\n","count_vect = CountVectorizer(min_df=2 ,stop_words=stopwords , ngram_range=(1,2))\n","tfidf_transformer = TfidfTransformer()\n","\n","X_train_counts = count_vect.fit_transform(train[\"Summary_Clean\"])        \n","X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n","\n","\n","X_new_counts = count_vect.transform(test[\"Summary_Clean\"])\n","X_test_tfidf = tfidf_transformer.transform(X_new_counts)\n","\n","checkcounts = count_vect.transform(check[\"Summary_Clean\"])\n","checktfidf = tfidf_transformer.transform(checkcounts)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a72af24a-8afd-46c2-8a9b-c0f34e06a8c3","_uuid":"2a55ae968bb538fed04ec512cfc76f46a2e76c9d"},"source":["## Fitiing Multinomial NB\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4fbe128a-83ef-4cad-9161-e8e0bf4f0275","_uuid":"3240a0e0dc18bf3ed26e16846109145b815c5aac","trusted":true},"outputs":[],"source":["from sklearn.naive_bayes import MultinomialNB\n","model1 = MultinomialNB().fit(X_train_tfidf , train[\"senti\"])\n","prediction['Multinomial'] = model1.predict_proba(X_test_tfidf)[:,1]\n","print(\"Multinomial Accuracy : {}\".format(model1.score(X_test_tfidf , test[\"senti\"])))\n","\n","check[\"multi\"] = model1.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"830c637b-c970-4de0-8bc5-874afc9ce233","_uuid":"de97924ca8a7070fbae7f4e3cfee42917353f1be"},"source":["## Fitiing Bernouli NB\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d6bf2247-112e-4e73-a5f0-5a9d436bceba","_uuid":"cc7784b7292590d9cc200bb274ea65785c40bca5","scrolled":true,"trusted":true},"outputs":[],"source":["from sklearn.naive_bayes import BernoulliNB\n","model2 = BernoulliNB().fit(X_train_tfidf,train[\"senti\"])\n","prediction['Bernoulli'] = model2.predict_proba(X_test_tfidf)[:,1]\n","print(\"Bernoulli Accuracy : {}\".format(model2.score(X_test_tfidf , test[\"senti\"])))\n","\n","check[\"Bill\"] = model2.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"2f1765a0-6300-47da-a3ae-5e6c54e4fa61","_uuid":"4e408529704d1472967dfd353432e5fc2dfa6015"},"source":["## Fitiing LogisticRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1ca2b0b-6dc3-4e4b-a604-598c40d2c35e","_uuid":"9fca90804b94b6191d3f8d7d13f9588ae9d8d346","trusted":true},"outputs":[],"source":["from sklearn import linear_model\n","logreg = linear_model.LogisticRegression(solver='lbfgs' , C=1000)\n","logistic = logreg.fit(X_train_tfidf, train[\"senti\"])\n","prediction['LogisticRegression'] = logreg.predict_proba(X_test_tfidf)[:,1]\n","print(\"Logistic Regression Accuracy : {}\".format(logreg.score(X_test_tfidf , test[\"senti\"])))\n","\n","check[\"log\"] = logreg.predict(checktfidf)## Predicting Sentiment for Check which was Null values for rating\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"1f3789b6-eae3-4f66-a1b2-fe774db287cf","_uuid":"b5e5368e9a1ab45dde7f9809a744e42a732ce9ec"},"source":["## Getting most occuring words in train set\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"d935f7e8-f500-451b-a498-bae5ef5f1792","_uuid":"1b184162bd29faf2e686ecce1dd9712a90705556","scrolled":true,"trusted":true},"outputs":[],"source":["words = count_vect.get_feature_names()\n","feature_coefs = pd.DataFrame(\n","    data = list(zip(words, logistic.coef_[0])),\n","    columns = ['feature', 'coef'])\n","feature_coefs.sort_values(by=\"coef\")"]},{"cell_type":"markdown","metadata":{"_cell_guid":"932b8a80-ddb8-491c-8a67-cc5171126de0","_uuid":"8c68f174a9934d47bcc72aaf9cd66b3d522c8e8c"},"source":["## Lets find out which classifier is doing what"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c4a865d3-37af-4dff-92fe-06c651364e2c","_uuid":"bf7f6615a4d7b7d5226f9a0a75c40bb746fe7228","trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"7f6519c1-8144-4e27-af7a-94fcf3010e37","_uuid":"c5d58f9f66cfea47cda26c53730bfa03b1ea6c3e","trusted":true},"outputs":[],"source":["def formatt(x):\n","    if x == 'neg':\n","        return 0\n","    if x == 0:\n","        return 0\n","    return 1\n","vfunc = np.vectorize(formatt)\n","\n","cmp = 0\n","colors = ['b', 'g', 'y', 'm', 'k']\n","for model, predicted in prediction.items():\n","    if model not in 'Naive':\n","        false_positive_rate, true_positive_rate, thresholds = roc_curve(test[\"senti\"].map(vfunc), predicted)\n","        roc_auc = auc(false_positive_rate, true_positive_rate)\n","        plt.plot(false_positive_rate, true_positive_rate, colors[cmp], label='%s: AUC %0.2f'% (model,roc_auc))\n","        cmp += 1\n","\n","plt.title('Classifiers comparaison with ROC')\n","plt.legend(loc='lower right')\n","plt.plot([0,1],[0,1],'r--')\n","plt.xlim([-0.1,1.2])\n","plt.ylim([-0.1,1.2])\n","plt.ylabel('True Positive Rate')\n","plt.xlabel('False Positive Rate')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"_cell_guid":"3a0e832c-ac72-4bb4-abee-6ea1c057b554","_uuid":"6c732f04807cc36e931ba54a0f5de7af3039d615"},"source":["## Lets see precision  and recall  of  different  classifiers\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"685fabad-8cc6-4823-82db-5b85d41e6b07","_uuid":"8a6d626be55be9763aeec43881cb0e99268e3664"},"source":["![Precision_Recall](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/525px-Precisionrecall.svg.png)"]},{"cell_type":"code","execution_count":null,"metadata":{"_uuid":"a38640a5eebd3445966c6302de2fa5f7db45a560","scrolled":true,"trusted":true},"outputs":[],"source":["test.senti = test.senti.replace([\"pos\" , \"neg\"] , [True , False] )"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"1aef6c14-a525-4880-992a-9de2d5d51987","_uuid":"cd8b8d9474933bd0ec03a112caaf40d3118c15a8","scrolled":true,"trusted":true},"outputs":[],"source":["keys = prediction.keys()\n","for key in ['Multinomial', 'Bernoulli', 'LogisticRegression']:\n","    print(\" {}:\".format(key))\n","    print(metrics.classification_report(test[\"senti\"], prediction.get(key)>.5, target_names = [\"positive\", \"negative\"]))\n","    print(\"\\n\")"]},{"cell_type":"markdown","metadata":{"_cell_guid":"b6e0a360-0679-4a9c-b926-b62d29711dec","_uuid":"57ccfe020ea6bd0f999026a24aae722e5aee0905"},"source":["## Let test our classifiers with some handwritten samples\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b7c724c3-8371-4668-8c7a-e1647389b4e3","_uuid":"b50248fed62b75959a19a020e3bdbe1816a801aa","trusted":true},"outputs":[],"source":["def test_sample(model, sample):\n","    sample_counts = count_vect.transform([sample])\n","    sample_tfidf = tfidf_transformer.transform(sample_counts)\n","    result = model.predict(sample_tfidf)[0]\n","    prob = model.predict_proba(sample_tfidf)[0]\n","    print(\"Sample estimated as %s: negative prob %f, positive prob %f\" % (result.upper(), prob[0], prob[1]))\n","\n","test_sample(logreg, \"The product was good and easy to  use\")\n","test_sample(logreg, \"the whole experience was horrible and product is worst\")\n","test_sample(logreg, \"product is not good\")\n"]},{"cell_type":"markdown","metadata":{"_cell_guid":"a308cc57-0854-4399-916f-53f3b77b1931","_uuid":"e20eac56a0fc3f288bc5da068ce8cb304118ea62"},"source":["## Here is predicted valuesof classifiers for check on the basis of review text"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"8cbeb076-c8e9-4ade-b3a6-a7fe840c5b6c","_uuid":"5b6b4a8a622fc316bd90020b00e4b5a9174bd249","trusted":true},"outputs":[],"source":["check.head(10)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"40e0b5a2-02e2-4f87-a0a0-b9c159363171","_uuid":"b73de1dc5f6866c5b9e4f6717c5ca8b3bba3930f","trusted":true},"outputs":[],"source":["from wordcloud import WordCloud, STOPWORDS\n","stopwords = set(STOPWORDS)\n","\n","\n","mpl.rcParams['font.size']=12                #10 \n","mpl.rcParams['savefig.dpi']=100             #72 \n","mpl.rcParams['figure.subplot.bottom']=.1 \n","\n","\n","def show_wordcloud(data, title = None):\n","    wordcloud = WordCloud(\n","        background_color='white',\n","        stopwords=stopwords,\n","        max_words=300,\n","        max_font_size=40, \n","        scale=3,\n","        random_state=1 # chosen at random by flipping a coin; it was heads\n","        \n","    ).generate(str(data))\n","    \n","    fig = plt.figure(1, figsize=(15, 15))\n","    plt.axis('off')\n","    if title: \n","        fig.suptitle(title, fontsize=20)\n","        fig.subplots_adjust(top=2.3)\n","\n","    plt.imshow(wordcloud)\n","    plt.show()\n","    \n","show_wordcloud(senti[\"Summary_Clean\"])\n"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"06904773-5d5a-42c2-b1ef-b090640de2c2","_uuid":"94dd43ba61c11b6c7b13663d49b20b2153ef05c3","collapsed":true,"trusted":false},"outputs":[],"source":["show_wordcloud(senti[\"Summary_Clean\"][senti.senti == \"pos\"] , title=\"Postive Words\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"4fa3c881-b7ef-41ac-ad8d-52f221cf7315","_uuid":"b748fdc88a520b5e9989349efe24b2ce572e71e0","collapsed":true,"trusted":false},"outputs":[],"source":["show_wordcloud(senti[\"Summary_Clean\"][senti.senti == \"neg\"] , title=\"Negitive words\")"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"01146775-1a28-428e-9351-9e8a6cf03b98","_uuid":"723db44c7421c6d08229b1e53dcfb4db4fe32090","collapsed":true,"trusted":false},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.11.0 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.0"},"vscode":{"interpreter":{"hash":"5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"}}},"nbformat":4,"nbformat_minor":1}
